{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is intended to run on a high-end GPU, as it requires a fairly significant amount of computational power.\n",
        "Moreover, this notebook contains some redundant code compared to the main project. Due to performance constraints, it has been optimized to run on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W62uarGSO5-c"
      },
      "outputs": [],
      "source": [
        "# path\n",
        "path_img_s2 = \"/content/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHlG79tMMvWf",
        "outputId": "4d32b1d4-2b0c-4861-bd0a-faba0cf9d55d"
      },
      "outputs": [],
      "source": [
        "# Connect datashare, transfer to the machine and unzip\n",
        "# mount gdrive to save the weight\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! cp /content/drive/MyDrive/Fac/Master/Remote_sensing/data.zip /content/\n",
        "# unzip\n",
        "! cd /content && unzip data.zip\n",
        "# i don't remove archive to save machine time\n",
        "\n",
        "#\n",
        "# do mount point to save output picture\n",
        "! ln -s /content/drive/MyDrive/Fac/Master/Remote_sensing/output/ /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-pNaSyQesmj",
        "outputId": "c4616660-0b4a-42af-fab3-207ab4a92068"
      },
      "outputs": [],
      "source": [
        "! pip install torchange rasterio opencv-python numpy pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Wfq9-LjFfETc",
        "outputId": "e6026bff-17ae-4f65-b9fa-7a18e7d3906e"
      },
      "outputs": [],
      "source": [
        "# do the import\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "def checkpoints_downloader(model_type):\n",
        "    # Dummy function to simulate downloading checkpoints\n",
        "    print(f\"Checking and downloading checkpoints for model type: {model_type} if needed.\")\n",
        "    path_of_model_base = \"/content/models/\"\n",
        "    os.makedirs(path_of_model_base, exist_ok=True)\n",
        "    name_of_model_file = f\"vit_{model_type.lower()}.pth\"\n",
        "    if not os.path.exists(os.path.join(path_of_model_base, name_of_model_file)):\n",
        "        print(f\"Model {name_of_model_file} not found. Proceeding to download.\")\n",
        "        # downloading model\n",
        "        match model_type:\n",
        "            case \"h\":\n",
        "                url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
        "            case \"l\":\n",
        "                url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\"\n",
        "            case \"b\":\n",
        "                url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
        "            case _:\n",
        "                raise ValueError(\"Invalid model type. Choose from 'h', 'l', or 'b'.\")\n",
        "        urlretrieve(url, os.path.join(path_of_model_base, name_of_model_file))\n",
        "        print(f\"Model {name_of_model_file} downloaded successfully.\")\n",
        "    else:\n",
        "        print(f\"Model {name_of_model_file} already exists. No download needed.\")\n",
        "\n",
        "    return os.path.join(path_of_model_base, name_of_model_file)\n",
        "\n",
        "# checkpoints_downloader(\"b\")\n",
        "checkpoints_downloader(\"h\")\n",
        "# checkpoints_downloader(\"l\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyhq9rn_SZ14"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "from torchange.models.segment_any_change import AnyChange, show_change_masks\n",
        "from skimage.segmentation import find_boundaries\n",
        "from torchange.models.segment_any_change.segment_anything.utils.amg import (\n",
        "    area_from_rle,\n",
        "    box_xyxy_to_xywh,\n",
        "    rle_to_mask,\n",
        "    MaskData\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import rasterio\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def aggregate_mask(mask_data):\n",
        "  # code rearrange from \"https://github.com/Z-Zheng/pytorch-change-models/\"\n",
        "    assert isinstance(mask_data, MaskData)\n",
        "    anns = []\n",
        "    for idx in range(len(mask_data[\"rles\"])):\n",
        "        ann_i = {\n",
        "            \"segmentation\": rle_to_mask(mask_data[\"rles\"][idx]),\n",
        "            \"area\": area_from_rle(mask_data[\"rles\"][idx]),\n",
        "        }\n",
        "        if 'boxes' in mask_data._stats:\n",
        "            ann_i['bbox'] = box_xyxy_to_xywh(mask_data[\"boxes\"][idx]).tolist()\n",
        "        anns.append(ann_i)\n",
        "\n",
        "    if len(anns) == 0:\n",
        "        return\n",
        "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
        "\n",
        "    img = np.zeros((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1]), np.int16)\n",
        "\n",
        "    for ann in sorted_anns:\n",
        "        m = ann['segmentation']\n",
        "        img[m] = 255\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def compute_change_mask_AnyChange(city, path_data=\"/content/data/S2\", plot_change=False):\n",
        "  # initialize AnyChange\n",
        "  m = AnyChange('vit_h', sam_checkpoint='/content/models/vit_h.pth') # select SAM model\n",
        "\n",
        "  # customize hyperparameters of SAM mask generator\n",
        "  m.make_mask_generator(\n",
        "      points_per_side=16,\n",
        "      stability_score_thresh=0.90,\n",
        "  )\n",
        "  # customize AnyChange hyperparameters\n",
        "  m.set_hyperparameters(\n",
        "      change_confidence_threshold=165,\n",
        "      use_normalized_feature=True,\n",
        "      bitemporal_match=True,\n",
        "  )\n",
        "\n",
        "  imageA = cv2.imread(os.path.join(path_data, f\"{city}/pair/img1.png\"), 1)\n",
        "  imageB = cv2.imread(os.path.join(path_data, f\"{city}/pair/img2.png\"), 1)\n",
        "  # convert image to RGB for SAM\n",
        "  imageA_ = cv2.cvtColor(imageA, cv2.COLOR_BGR2RGB)\n",
        "  imageB = cv2.cvtColor(imageB, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # compute change mask with AnyChange\n",
        "  changemasks, _, _ = m.forward(imageA, imageB)\n",
        "\n",
        "  if plot_change :\n",
        "\n",
        "    fig, axes = show_change_masks(imageA, imageB, changemasks)\n",
        "    plt.show()\n",
        "\n",
        "  # Compute a binary mask from the aggregation of the different masks.\n",
        "  change_mask = aggregate_mask(changemasks)\n",
        "  return change_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiIdZ8NgSPjD"
      },
      "outputs": [],
      "source": [
        "# duplicate from main.py and utils.py\n",
        "def get_city_names_from_folder(folder_path: Path) -> list[str]:\n",
        "    city_names = []\n",
        "    for city_dir in sorted([p for p in folder_path.iterdir() if p.is_dir()]):\n",
        "        city_names.append(city_dir.name)\n",
        "    return city_names\n",
        "\n",
        "def evaluate_change_map(change_map: np.ndarray, ground_truth: np.ndarray)->dict:\n",
        "    \"\"\"\n",
        "    Évalue la carte de changement en calculant les métriques de performance.\n",
        "\n",
        "    Args:\n",
        "        change_map: Carte de changement (0->255)\n",
        "        ground_truth: Ground truth (0 ou 1)\n",
        "    \"\"\"\n",
        "    #On transforme la carte de changement (0->255) en une image binaire (0 ou 1)\n",
        "    pred = (change_map > 0).astype(np.uint8)\n",
        "    gt = (ground_truth > 0).astype(np.uint8)\n",
        "    TP = np.sum((pred == 1) & (gt == 1))\n",
        "    TN = np.sum((pred == 0) & (gt == 0))\n",
        "    FP = np.sum((pred == 1) & (gt == 0))\n",
        "    FN = np.sum((pred == 0) & (gt == 1))\n",
        "\n",
        "    # Métriques\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # IoU (Intersection over Union) / Jaccard Index\n",
        "    iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "    # Kappa de Cohen (corrige le hasard)\n",
        "    po = accuracy  # Accord observé\n",
        "    pe = ((TP + FP) * (TP + FN) + (FN + TN) * (FP + TN)) / ((TP + TN + FP + FN) ** 2)\n",
        "    kappa = (po - pe) / (1 - pe) if (1 - pe) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1_score,\n",
        "        'IoU': iou,\n",
        "        'Kappa': kappa\n",
        "    }\n",
        "\n",
        "def mean_metric(metrics_list, key):\n",
        "    return np.round(np.mean([m[key] for m in metrics_list]), 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pyuWqYlPk0A"
      },
      "outputs": [],
      "source": [
        "def bulk_process_change_masks(path_img):\n",
        "  path_s2 = os.path.join(path_img, \"S2\")\n",
        "  city_name = sorted(get_city_names_from_folder(Path(path_s2)))\n",
        "\n",
        "  metrics = []\n",
        "\n",
        "  for city in tqdm(city_name):\n",
        "    change_mask = compute_change_mask_AnyChange(city, path_data=path_s2, plot_change=False)\n",
        "\n",
        "    with rasterio.open(os.path.join(path_img, f\"ground_truth/{city}/cm/{city}-cm.tif\")) as src:\n",
        "        ground_truth =  src.read()[0]\n",
        "\n",
        "\n",
        "    metric = evaluate_change_map(change_mask, ground_truth)\n",
        "    metrics.append(metric)\n",
        "\n",
        "  return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuLYqz9282HC"
      },
      "outputs": [],
      "source": [
        "def compute_several_distrib(metrics, key):\n",
        "  mean = np.round(np.mean([m[key] for m in metrics]), 4)\n",
        "  std = np.round(np.std([m[key] for m in metrics]), 4)\n",
        "  min = np.round(np.min([m[key] for m in metrics]), 4)\n",
        "  max = np.round(np.max([m[key] for m in metrics]), 4)\n",
        "  print(f\"{key}\\n Mean: {mean}, Std: {std}, Min: {min}, Max: {max}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compute Metrics for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KENndajiVYZq",
        "outputId": "548a9d33-a805-445b-ee48-cd26f15e9a53"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"Accuracy: \", mean_metric(metrics, 'Accuracy'),\n",
        "    \"Precision: \", mean_metric(metrics, 'Precision'),\n",
        "    \"Recall: \", mean_metric(metrics, 'Recall'),\n",
        "    \"F1-Score: \", mean_metric(metrics, 'F1-Score'),\n",
        "    \"IoU: \", mean_metric(metrics, 'IoU'),\n",
        "    \"Kappa: \", mean_metric(metrics, 'Kappa')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-NfX8Ug9Uok",
        "outputId": "d40096c5-9f96-4a75-ebd0-679f2c8c599f"
      },
      "outputs": [],
      "source": [
        "compute_several_distrib(metrics, 'F1-Score')\n",
        "compute_several_distrib(metrics, 'IoU')\n",
        "compute_several_distrib(metrics, 'Kappa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utf0Tzp9Heh0"
      },
      "outputs": [],
      "source": [
        "# get image for the report\n",
        "changemask = compute_change_mask_AnyChange(\"beirut\", plot_change=False)\n",
        "img_1 = cv2.imread(\"/content/data/S2/beirut/pair/img1.png\", 1)\n",
        "img_2 = cv2.imread(\"/content/data/S2/beirut/pair/img2.png\", 1)\n",
        "img1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)\n",
        "ground_truth = cv2.imread(\"/content/data/ground_truth/beirut/cm/cm.png\", 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "jUsX85SSIqL5",
        "outputId": "8e1fe0cc-9698-440d-9c34-3d346aa0da82"
      },
      "outputs": [],
      "source": [
        "# print images for the report\n",
        "fig, axes = plt.subplots(1, 4, figsize=(12, 4), sharex=True, sharey=True)\n",
        "axes[0].imshow(img1)\n",
        "axes[0].set_title(\"Image before (t1)\")\n",
        "\n",
        "axes[1].imshow(img2)\n",
        "axes[1].set_title(\"Image after (t2)\")\n",
        "\n",
        "\n",
        "axes[2].imshow(changemask)\n",
        "axes[2].set_title(\"Change map\")\n",
        "\n",
        "axes[3].imshow(ground_truth)\n",
        "axes[3].set_title(\"Ground truth\")\n",
        "\n",
        "for ax in axes:\n",
        "    ax.axis('off')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
